{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os, time\n",
    "import numpy as np\n",
    "from model.net import FashionNet\n",
    "from load_dataset import custom_dset, collate_fn, denorm\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "import argparse\n",
    "from utils import AverageMeter, AverageAcc\n",
    "from tqdm import tqdm\n",
    "from focal_loss import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "\n",
    "CSS = \"\"\"\n",
    ".output {\n",
    "    flex-direction: row;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "HTML('<style>{}</style>'.format(CSS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, test_loader, accuracy):\n",
    "\n",
    "\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    criterion = FocalLoss(gamma=2, alpha=0.25)\n",
    "    label_map = { v:k for k,v in test_loader.dataset.label_map.items()} \n",
    "\n",
    "    bar = tqdm(total=len(test_loader))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for it, (imgs, labels, img_ids) in enumerate(test_loader):\n",
    "\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            # run input through the network\n",
    "            preds = net(imgs)\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            accuracy.update(preds.data, labels.data, topk=(1, 5))\n",
    "            losses.update(loss.item(), imgs.size(0))\n",
    "            bar.update()\n",
    "            if it % 100 == 0:\n",
    "                # save to disk first batch of results for every epoch\n",
    "                for i,im in enumerate(imgs):\n",
    "                    im = im.data.cpu().numpy()\n",
    "                    im = denorm(im.transpose(1,2,0))[...,::-1]\n",
    "\n",
    "                    _, inds = torch.max(preds, 1)\n",
    "                    pred = label_map[inds[i].item()]\n",
    "                    gt_label = label_map[labels[i].item()]\n",
    "\n",
    "                    fname =  str(img_ids[i]) + '__' 'Gt:' + gt_label + 'Pred:' + pred + '.jpg'\n",
    "                    cv2.imwrite(os.path.join(out_path, fname),  im)\n",
    "\n",
    "        bar.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/520 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Test Dataset of size: 12476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 71/520 [00:41<04:06,  1.82it/s]"
     ]
    }
   ],
   "source": [
    "out_path = './data/show_test'\n",
    "if not os.path.isdir(out_path):\n",
    "    os.mkdir(out_path)\n",
    "\n",
    "\n",
    "# check checkpoints folder for model_name\n",
    "model_name = 'pnet_0.92.pth'\n",
    "\n",
    "# get the current working directory\n",
    "root = os.getcwd()\n",
    "\n",
    "# load model\n",
    "model_path = os.path.join(root, 'checkpoints', model_name)\n",
    "model = torch.load(model_path)\n",
    "label_map = model['label_map']\n",
    "net = FashionNet(len(label_map))\n",
    "net.load_state_dict(model['net'])\n",
    "\n",
    "net = net.cuda()\n",
    "net.eval()\n",
    "\n",
    "\n",
    "test_pretrain = custom_dset('test_pretrain', label_map)\n",
    "print('Pretrain Test Dataset of size: {}'.format(len(test_pretrain)))\n",
    "test_loader = DataLoader(test_pretrain, batch_size=24, shuffle=False, collate_fn=collate_fn, num_workers=4)\n",
    "\n",
    "accuracy = AverageAcc(label_map)\n",
    "test(net, test_loader, accuracy)\n",
    "\n",
    "# get accuracies per class and the averages \n",
    "topk_dict, top1, top5 = accuracy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# collect accuracies into lists for printing purpose \n",
    "lc = [k for k in label_map]\n",
    "t1 = [v[1] for k,v in topk_dict.items()]\n",
    "t2 = [v[5] for k,v in topk_dict.items()]\n",
    "avg = [round(top1, 2), round(top5, 2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset =  custom_dset('train_pretrain')\n",
    "lc_train = [trainset.freq[c] for c in lc]\n",
    "# display train set statitstics \n",
    "df_dset = pd.DataFrame(np.vstack((lc, lc_train)).transpose(), index=['Trainset']*len(label_map),\n",
    "                       columns=['Category', 'Data examples'])\n",
    "display(df_dset)\n",
    "\n",
    "\n",
    "# display dataset statitstics \n",
    "df_dset = pd.DataFrame(np.vstack( (lc, [v[1] for _,v in accuracy.count.items()])).transpose(), columns=['Category', 'Data examples'],\n",
    "                       index=['Testset']*len(label_map))\n",
    "display(df_dset)\n",
    "\n",
    "# concatenate accuracy lists in numpy array of shape (num_classes, num_columns)\n",
    "df_class = pd.DataFrame(np.vstack( (lc, t1, t2)).transpose(), columns=['Category', 'Top1', 'Top5'], index=['TestAcc']*len(label_map))\n",
    "df_avg = pd.DataFrame(np.array(avg).reshape(1,2), columns=['Top1', 'Top5'], index=['Average'])\n",
    "\n",
    "# display the accuracies \n",
    "display(df_class)\n",
    "display(df_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
